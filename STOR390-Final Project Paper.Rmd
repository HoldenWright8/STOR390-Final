---
title: "Consumer Lending in the FinTech Era: Minimizing both risk and bias"
author: "Holden Wright"
output: pdf_document
date: "2024-12-06"
fontsize: 12pt
header-includes:
  - \usepackage{titling}
  - \setlength{\droptitle}{-0.1in}
---

# Introduction

For many Americans, owning a home is a lifelong dream, but the path to achieving that dream is not equal for everyone. According to data collected by the Home Mortgage Disclosure Act (HMDA), 16.1 million mortgage applications were submitted in 2023 (HMDA, 2023). Lending institutions are tasked with evaluating these applications based on financial metrics such as credit score and loan-to-value ratio, without considering personal characteristics like race, gender, or religion. However, data from the Federal Financial Institutions Examination Council (FFIEC) reveals a stark disparity in loan denial rates across racial groups. In 2023, African American and Hispanic-White applicants faced denial rates of 16.6% and 12.0%, respectively, for "first lien, one- to four-family, site-built, owner-occupied conventional, closed-end home purchase loans." In contrast, Asian and non-Hispanic-White applicants experienced significantly lower denial rates at 9.0% and 5.8% (CFPB, 2024). This disparity raises critical questions about fairness in lending practices. While credit risk assessments are designed to evaluate financial risk objectively, research suggests that minority borrowers often face bias even when their credit metrics are comparable to those of non-minority borrowers. In their paper "Consumer-lending discrimination in the FinTech Era", Robert Bartlett, Adair Morse, Richard Stanton, and Nancy Wallace investigate this issue, aiming to prove that minorities pay significantly higher interest rates on mortgage loans than non-minorities with equivalent credit risk metrics. Looking towards the future in this new era of AI driven analysis, they also investigate whether FinTech platforms reduce or perpetuate lending disparities. This paper critiques their methods and, through the lens of Rawlsian justice, argues that while FinTech algorithms show promise in reducing human bias, they still fall short of achieving true equity by perpetuating systemic disparities through data-driven decision-making.

# Analysis of Methods

Through their research and analysis, the authors aim to prove that minority borrowers pay significantly higher interest rates on mortgage loans even when controlling for credit risk metrics, change over time, and geographical factors. The authors' methodology is based on the integration of four datasets: McDash (loan-level performance data), ATTOM (property and loan-level data), HMDA (loan origination data), and Equifax (borrower credit data). By combining these datasets, they create a novel dataset that is capable of controlling for detailed borrower, lender, and loan characteristics. In this section, I will
provide a thorough explanation of their analysis and attempt to fill in any gaps in their research. Subsequently, I will offer my own critiques of their approach and suggest improvements

## Novel Analysis

The first thing that separates their research from past literature is the ability to account for an individuals credit risk and thus identify discrimination between individuals with equalivent risk. This is made possible by the role of government-sponsored enterprises (GSEs) and the Federal Housing Administration (FHA). GSEs determine credit-risk pricing adjustments using an 8 by 8 matrix of loan-to-value ratios (LTVs) and credit scores called loan-level price adjustments (LLPAs). FHA loans work similarly and are based off the GSEs' LLPA grid but are less rigid and do not employ as strict risk-based pricing.

The researcher's base model regresses the mortgage interest rate on an indicator variable for whether the individual is black or latinx plus dummies for the 64 GSE grid levels interacted with year/month and whether the loan was a cash-out refinance plus a lender variable interacted with year. This model allows the researchers to capture pricing from the grid, as well as different pricing methods for cash-out refinances, differential pricing by lender, and fluctuations over time. The inclusion of a lender fixed effect is especially useful, as it controls for differences in lending practices across institutions and helps to isolate the role of borrower demographics in interest rate pricing.The model also includes a fixed effect for loan size to account for its effect on the interest rate.

$interest\ rate = \alpha I(Latinx\ or\ Black)_i + \mu cashout\ x\  GSE\ grid\ x\ year/month\ + \mu Lender\ x\ year/month\ + \mu Amount\ decile\ + \epsilon_{it}$

After running this model on the data the researchers find significant levels of arbitrary discrimination across all types of loans. Another point of the research is to determine whether FinTech lenders, who use AI to determine interest rates and approvals rather than traditional face to face lenders, also discriminate against minorities in their lending practices. To test this the researchers employ the difference-in-differences framework. This method compares changes in interest rates between FinTech and non-FinTech lenders, while controlling for borrower creditworthiness. 

$interest\ rate = Non\text{-}FinTech\ x\ Minority +\ FinTech\ x\ Minority +\ \mu cashout\ x$
$GSE\ grid\ x\ year/month\ +\ \mu Lender\ x\ year/month\ +\ \mu Amount\ decile\ +\ \epsilon_{it}$

They find that FinTech lenders exhibit roughly the same level of discrimination for GSE loans and marginally lower levels for FHA loans, although still statistically significant amounts. The assumption fueling this approach is that, aside from FinTech-specific practices, lending outcomes for comparable borrowers would be the same across the two groups. While the difference-in-differences framework provides an experimental design to assess the difference in discrimination between FinTech and traditional lenders, the authors do not test the validity of the parallel trends assumption, leaving a potential gap in their analysis. 

The paper then moves on to testing the effect of the passage of time on rates and if it can explain some of the bias. In this section the researchers note the importance of shopping behavior in equal treatment for loan terms. Shopping behavior refers to the propensity of the buyer to get quotes from different lending institutions in search of the cheapest option. The researchers then theorize that the entrance of FinTech and algorithmic lending could have created an environment that was more conducive to this type of behavior. An additional reason to investigate loans over time is that for loans issued after 2011, post-crisis reforms to Regulation Z prohibited loan originators from receiving compensation based on the interest rate or other loan terms. This regulation was meant to reduce the incentive of brokers to place borrowers into high-cost loans. In order to look at the effect of passing time the researchers plot the difference in minority and non-minority rates over time. The plot exhibits no consistent trend or change over time suggesting that neither the introduction of FinTech lending nor changes to regulation has had any notable effect on outcomes. 

While this section does not provide any evidence against their claim that minority borrowers are arbitrarily discriminated against, it does create a minor hole in their analysis. The researchers have mentioned the importance of borrower behavior and how the propensity to search for the lowest rate can have an affect on outcomes. So while they do test this theory using the introduction of additional lending options as a basis point, they do not have an explicit control for differences in behavior between races, nor do they examine whether one exists. The existence of a difference in borrower behavior between races would not necessarily disprove that arbitrary discrimination exists, but it may lend a path to helping ease this burden by making comparing rates more accessible or offering more personal finance classes in schools to inform people of the benefits of rate shopping. 

In the next section the authors examine the effect of geography on rates. To look at the effect they use census data to analyze whether discrimination is higher in areas with larger minority share. Their model includes all the prior controls and this time the minority indicator is interacted with an indicator for minority share decile (a metric from 1-10 that measures the concentration of minorities in a given geographical location).

$interest\ rate = \alpha I(Latinx\ or\ Black)_i\ x\ Minority\text{-}share\ decile + \mu cashout\ x\  GSE\ grid\ x\ year/month\ + \mu Lender\ x\ year/month\ + \mu Amount\ decile\ + \epsilon_{it}$

They find that overall mortgage rates are higher for all borrowers in high minority concentrated areas and on top of that discrimination is higher as well. A minority in the lowest decile zone has a statistically insignificant difference in rates from a non-minority. This shows that racist sentiments may be higher in areas of higher minority concentration. Because of the double effect of both higher overall rates and higher discrimination, a minority borrower taking out a GSE purchase loan in the highest concentrated minority-share census tract pays, on average, 13.8 basis points more than an otherwise-equivalent non-minority borrower in the lowest concentrated minority-share census tract. For FHA purchase loans, the difference is even larger at 16.2 basis points. In order to account for the different costs in different areas, the authors control for differential default risk. They use variables for whether each loan went into foreclosure/REO, 60-days-plus delinquent, or 90-days-plus delinquent. These post default realizations would obviously not have been available to lenders at the time the loans were initially issued but even conditioning on these three measures does not make a difference in their estimates. They then control for prepayment risk, state foreclosure laws, and rent levels again finding that these make no difference. 

After conducting their primary research and finding significant arbitrary discrimination against minority borrowers the authors conduct additional robustness tests to further validate their results. In this section they explore the effects of put-back risk and HMDA ethnicity/race designations.

Put-backs are a fee payed from the lender to the GSE  when the documentation on income, credit score, loan purpose, or property value is falsified or missing. Because of post-2008 regulation put-back payments were made almost completely irrelevant. To test whether put-back risk had an effect on rates they conduct three analyses. They run a regression from only 2013 on, after put-backs had become negligible. Second they run a regression using only high quality borrowers, credit scores above 700, as put-backs would not be a risk for them. And thirdly they include an indicator for banks vs non-bank lending institutions, as put-backs are not as relevant for non-bank lenders. They conclude from these three tests that put-backs have little effect on the coefficient on minority borrowers. 

In the author's initial analysis minority designation is determined by combining self-reported data from the HMDA with the borrower’s likely race based on a race name-categorization algorithm for mortgages that lack an indicator for borrower race. This algorithm could misclassify some borrowers, and this could be correlated with the loan interest rate. To remove potential misclassification error they run an additional two regressions: one using only observations for which race or ethnicity is provided by HMDA and another that sets the treatment variable to 1 if either the borrower or the first co-borrower is Latinx or Black. In both cases the results are very similar to the original model, confirming that their results are not driven by errors in classification. 

All of their analysis to this point had been conducted on a data set from 2009-2015. The next portion of their research is conducted on a data set from 2018-2019 that allowed the researchers to control for points and total up-front loan costs. Borrowers can choose to pay “discount points,” which is an up-front lump sum, to a lender to reduce their loan's interest rate. They can also choose to pay “negative points” to get a credit from the lender, in return for paying a higher loan interest rate. They re-run the same models described above on the 2018-2019 data not controlling for points in order to directly compare their findings in the two data sets. The results from running their original model are confirmed again on the newer data set but when they run the model including FinTech indicators, they find that for FHA refinance loans the FinTech x Minority variable has a statistically insignificant coefficient. This finding shows that for that style of loan FinTechs exhibit no arbitrary discrimination. However, for all other types of loans FinTechs exhibit similar levels of discrimination to non FinTechs. After comparing the previously run models on the more recent data they run a new model controlling for points. This model does not exhibit any differences in findings from their earlier models and again points to discrimination. 

The researchers conclude that arbitrary discrimination is clearly a problem for both FinTech and traditional lenders. Although they discover that for FHA refinance loans FinTech algorithms have reduced discrimination, this is not apparent for any other form of loan. This points to the pricing strategies of the algorithms creating bias which may stem from the data they are trained on. The authors offer some insight into the role of the GSE in removing bias, stating that it incentivizes the use of solely credit-linked variables. The authors claim this role is less well understood and needs to be factored in to future GSE reforms and must be supported in conventional privatized mortgage market. 

## Critique of Methodology

The authors' use of a difference-in-differences (DiD) framework is a valid approach to comparing lending practices between FinTech and traditional lenders. An issue arises with the assumption of parallel trends, a necessary assumption for the validity of the DiD method. By not testing this assumption, the authors fail to confirm that in the absence of FinTech-specific practices, the trends in interest rates would have been the same for both types of lenders. The parallel trends assumption is needed in order to conclude that observed differences in outcomes are attributable to the FinTech factor rather than pre-existing trends in the data. The omission of testing this assumption leaves a gap in their analysis. This weakens the conclusion that FinTech lenders exhibit similar or marginally lower discrimination than traditional lenders.

Another flaw in the FinTech comparison is that not necessarily the same types of borrowers use FinTech lenders as those who use traditional lenders. Unobserved differences in borrowers could be obscuring the level of discrimination shown by FinTech lenders. While the authors do mention this as a potential issue and claim that the effect would be negligible, by not attempting to control for the difference or test that it does not matter they are slightly weakening their analysis. 

Later in the paper the authors acknowledge the potential influence of borrower behavior on interest rates, specifically the propensity to shop for the lowest rates, yet they do not explicitly control for potential racial differences in this behavior. Differences in financial literacy, access to information, or awareness of rate shopping opportunities across racial groups could influence the results. Without accounting for this behavior, the authors risk overlooking an important factor that could contribute to the observed disparities in rates. While this does not necessarily disprove the existence of discriminatory practices, it points to a potential area for intervention. For instance, promoting financial literacy programs or increasing access to rate comparison tools could help mitigate these disparities by allowing borrowers of all racial backgrounds to make more informed decisions. Thus, an examination of how borrower behavior varies across races could improve the authors' understanding of the factors contributing to the disparities they observe and offer a potential solution going forward.

# Analysis of Normative Consideration

The persistence of racial disparities in mortgage lending, as highlighted in "Consumer-lending discrimination in the FinTech Era", raises ethical concerns about the fairness of the lending system. Drawing on the principles of philosopher John Rawls, who prioritized the design of societal systems that benefit the least advantaged groups, we must evaluate the extent to which FinTech algorithms promote or undermine fairness in lending practices. Rawls’ concept of the veil of ignorance, designing institutions as if unaware of one’s own position in society, offers a compelling lens to assess the ethical implications of algorithmic lending. Using the veil of ignorance, a just system would eliminate biases based on inherent characteristics such as race or ethnicity, ensuring that all individuals have equitable access to credit opportunities.

FinTech algorithms are meant to remove human subjectivity but fall short of Rawlsian ideals due to their reliance on historical data that reflects systemic inequalities. By letting these past inequalities influence predictive models, algorithms risk perpetuating the same biases they are meant to eliminate. For example, a borrower’s zip code can serve as a proxy for race, creating discriminatory patterns in otherwise neutral lending decisions. Rawlsian justice would require that the inputs into the algorithm be examined and potentially excluded if they contribute to unjust outcomes, emphasizing fairness over predictive accuracy.

Rawls’ difference principle, which allows for social and economic inequalities only if they benefit the least advantaged, highlights a fail of the current system. The paper demonstrates that minority borrowers, even when controlling for credit risk, pay higher interest rates and face greater barriers to approval. This disparity contradicts Rawls' ideals by unfairly placing a burden on an already disadvantaged group. A fair lending system would actively work to fix such disparities, ensuring that the benefits of financial access are distributed equitably.

The use of FinTech algorithms also raises questions about transparency and accountability, both necessary components of a fair system under Rawls' principles. Lenders tend to treat their algorithms as proprietary black boxes, making it difficult for borrowers to challenge decisions or for regulators to assess fairness. Rawls' ethics would require more openness from FinTech institutions, necessitating that algorithms be subject to auditing to ensure that they align with principles of fairness and equity.

While FinTech algorithms hold promise for reducing human biases, their current usage falls short of the Rawls' ideal of justice. Addressing their shortcomings requires systemic reforms, the exclusion of biased inputs, and increased regulatory oversight. By aligning algorithmic lending practices with Rawls' principles, we can move closer to a system that provides equitable opportunities for everyone, regardless of race or ethnicity. This approach not only promotes fairness but also strengthens the integrity of the financial system as a whole.

# Conclusion

## Impact of Paper

Robert Bartlett, Adair Morse, Richard Stanton, and Nancy Wallace's paper makes a significant contribution to the field of financial economics by addressing longstanding questions about discrimination in mortgage lending. Their work constructs a novel and comprehensive dataset, merging, for the first time, four major mortgage data sources: McDash loan-level data from Black Knight Financial Services, property and loan-level data from ATTOM Data Solutions, loan origination data from HMDA, and loan-performance data from Equifax. This data set provides unprecedented detail on borrower demographics, loan terms, and lender characteristics. The paper overcomes the limitations of prior studies, such as reliance on outdated pre-2008 financial crisis data and the issue of omitted-variable bias. The paper's innovative methodology allows it to distinguish between discrimination and credit-risk differences observable to lenders but previously not to researchers. By leveraging their newly constructed dataset, the authors avoid the omitted variable bias that plagued previous research and reveal that, even when accounting for detailed credit-risk metrics, minority borrowers pay higher interest rates and face more significant barriers to mortgage approval. The impact of this research is profound: it not only advances our understanding of systemic bias in lending but also provides a foundation for policymakers and regulators to promote more equitable practices. Additionally, the findings have implications for the design and regulation of FinTech algorithms, highlighting the need for greater transparency and fairness in automated decision-making systems. This work contributes meaningfully to the broader pursuit of financial justice and equity in consumer lending.

## Future Work and Wrap-Up

Building on the insights from "Consumer-lending discrimination in the FinTech Era", there are multiple directions for future research in the field of fair lending practices and algorithmic decision-making. First, expanding the analysis to include more recent and diverse data sources could provide insights into how evolving market conditions and regulatory changes influence lending disparities. For example, using data from non-mortgage lending sectors, such as auto loans or personal loans, could help determine whether the findings are applicable across financial products. Secondly, additional research is needed to refine methods for detecting and mitigating algorithmic bias. Techniques like causal inference models and fairness-aware machine learning algorithms could be employed to better isolate discrimination from legitimate credit-risk factors. Further exploration of alternative algorithmic scoring methods, including explainable AI approaches, might offer insights into how transparency can improve fairness.

In conclusion, the research conducted by authors in "Consumer-lending discrimination in the FinTech Era" offers valuable insights into the discrimination within the lending industry and how it has been affected by the rise of FinTechs. The critique of their methodological framework, particularly on the use of the difference-in-differences approach, reveals some limitations to their analysis. The failure to account for variations in borrower behavior across racial groups may introduce some bias, and weakens the robustness of their conclusions. To address these concerns, additional controls or testing may be needed to ensure that they properly capture the dynamics influencing lending decisions. Additionally, the normative considerations surrounding the study highlight the ethical implications of algorithmic decision-making in lending. While the integration of technology into financial systems can promote efficiency and accessibility, it also raises concerns relating to transparency and algorithmic bias. The potential for perpetuating social inequalities calls for reform in the regulation of FinTech algorithms. In order to create an equitable financial system, future efforts must focus on enhancing algorithmic fairness by implementing stricter regulatory measures and improving transparency.


\newpage

# References

“FFIEC Publishes 2023 Data on Mortgage Lending | Consumer Financial Protection Bureau.” Consumer Financial Protection Bureau, 11 July 2024, www.consumerfinance.gov/about-us/newsroom/ffiec-publishes-2023-data-on-mortgage-lending.

Bartlett, Robert, et al. “Consumer-lending Discrimination in the FinTech Era.” Journal of Financial Economics, vol. 143, no. 1, May 2021, pp. 30–56, doi:10.1016/j.jfineco.2021.05.047.

Green, Dan. “HMDA Mortgage Data: 2023 Home Buyer Statistics.” Homebuyer.Com, 22 Sept. 2024, homebuyer.com/research/hmda-mortgage-statistics. Accessed 07 Dec. 2024. 









